### WGSA Stats

The CSV files in the directory provide data collected from the Condor logs and AWS Cost and Usage Reports after the WGSA workflow for 608 samples was completed. There were 70 jobs (annotations) ran on i3.8xlarge EC2 spot instances for each sample, plus an extra merging job on the headnode (172.21.255.58). Ideally, to annotate the 608 samples, only 608 * 71 = 43168 needed to be run. However, some of the jobs failed due to running out of memory when too many high memory consuming jobs were allocated to the same spot instance. Also some of the jobs were reported as failed by Galaxy when the RDS was not able to handle a sufficient number of connections to the database in the pool. After upgrading the RDS and defining appropriate memory requirements (by specifying RequestCpus) for different annotations in job description files for Condor, we were able to run all jobs without any failure and reach the spot instance limit 1000 set on the AWS account. The ``condor_stats_wgsa.csv`` contains data collected from the Condor log files that correspond with the WGSA jobs. As the jobs were executed on spot instances, there is not assurance that they will complete before the instance is terminated by AWS due to multiple reasons (another AWS user who placed a higher bid, capacity-oversubscribed, or no-capacity). Such jobs are marked by Condor as evicted and restarted as soon as another available spot instance is in the Condor pool. In effect, the CSV file may contain several lines for one jobs, one line for each execution of the job on a worker node. Jobs with status ``aborted`` were terminated by the user before they completed.

``aws_daily_raw.csv.gz`` is a raw daily AWS Cost and Usage Report generated by AWS and put to the S3 bucket. ``aws_daily_i3.8xlarge_wgsa.csv`` contains only i3.8xlarge spot instance cost for the WGSA runs extracted from ``aws_daily_raw.csv.gz``. ``UsageAmount/UnblendedCost`` gives an average instance cost per hour. The following command shows how quickly calculate a daily cost of the spot instances:

```sh
$ for ((i=19;i<=31;i=i+1)); do echo 2018-10-$i: \$`grep ^2018-10-$i aws_daily_i3.8xlarge_wgsa.csv | cut -d, -f 7 | paste -sd+ | bc`; done
```
